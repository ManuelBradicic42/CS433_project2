Vocab: #+-12345678=BKNOQRabcdefghx, vocab length: 27, max text length: 7
----------------------------------------------------------------------------------------------------
Layer                   Kernel Shape         Output Shape         # Params (K)      # Mult-Adds (M)
====================================================================================================
0_Conv2d               [3, 16, 3, 3]     [1, 16, 32, 128]                 0.45                 1.77
1_BatchNorm2d                   [16]     [1, 16, 32, 128]                 0.03                 0.00
2_LeakyReLU                        -     [1, 16, 32, 128]                    -                    -
3_Conv2d              [16, 16, 3, 3]     [1, 16, 32, 128]                 2.32                 9.44
4_BatchNorm2d                   [16]     [1, 16, 32, 128]                 0.03                 0.00
5_Conv2d               [3, 16, 1, 1]     [1, 16, 32, 128]                 0.06                 0.20
6_LeakyReLU                        -     [1, 16, 32, 128]                    -                    -
7_Dropout                          -     [1, 16, 32, 128]                    -                    -
8_Conv2d              [16, 16, 3, 3]      [1, 16, 16, 64]                 2.32                 2.36
9_BatchNorm2d                   [16]      [1, 16, 16, 64]                 0.03                 0.00
10_LeakyReLU                       -      [1, 16, 16, 64]                    -                    -
11_Conv2d             [16, 16, 3, 3]      [1, 16, 16, 64]                 2.32                 2.36
12_BatchNorm2d                  [16]      [1, 16, 16, 64]                 0.03                 0.00
13_Conv2d             [16, 16, 1, 1]      [1, 16, 16, 64]                 0.27                 0.26
14_LeakyReLU                       -      [1, 16, 16, 64]                    -                    -
15_Dropout                         -      [1, 16, 16, 64]                    -                    -
16_Conv2d             [16, 16, 3, 3]      [1, 16, 16, 64]                 2.32                 2.36
17_BatchNorm2d                  [16]      [1, 16, 16, 64]                 0.03                 0.00
18_LeakyReLU                       -      [1, 16, 16, 64]                    -                    -
19_Conv2d             [16, 16, 3, 3]      [1, 16, 16, 64]                 2.32                 2.36
20_BatchNorm2d                  [16]      [1, 16, 16, 64]                 0.03                 0.00
21_LeakyReLU                       -      [1, 16, 16, 64]                    -                    -
22_Dropout                         -      [1, 16, 16, 64]                    -                    -
23_Conv2d             [16, 32, 3, 3]       [1, 32, 8, 32]                 4.64                 1.18
24_BatchNorm2d                  [32]       [1, 32, 8, 32]                 0.06                 0.00
25_LeakyReLU                       -       [1, 32, 8, 32]                    -                    -
26_Conv2d             [32, 32, 3, 3]       [1, 32, 8, 32]                 9.25                 2.36
27_BatchNorm2d                  [32]       [1, 32, 8, 32]                 0.06                 0.00
28_Conv2d             [16, 32, 1, 1]       [1, 32, 8, 32]                 0.54                 0.13
29_LeakyReLU                       -       [1, 32, 8, 32]                    -                    -
30_Dropout                         -       [1, 32, 8, 32]                    -                    -
31_Conv2d             [32, 32, 3, 3]       [1, 32, 8, 32]                 9.25                 2.36
32_BatchNorm2d                  [32]       [1, 32, 8, 32]                 0.06                 0.00
33_LeakyReLU                       -       [1, 32, 8, 32]                    -                    -
34_Conv2d             [32, 32, 3, 3]       [1, 32, 8, 32]                 9.25                 2.36
35_BatchNorm2d                  [32]       [1, 32, 8, 32]                 0.06                 0.00
36_LeakyReLU                       -       [1, 32, 8, 32]                    -                    -
37_Dropout                         -       [1, 32, 8, 32]                    -                    -
38_Conv2d             [32, 64, 3, 3]       [1, 64, 4, 16]                18.50                 1.18
39_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
40_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
41_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
42_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
43_Conv2d             [32, 64, 1, 1]       [1, 64, 4, 16]                 2.11                 0.13
44_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
45_Dropout                         -       [1, 64, 4, 16]                    -                    -
46_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
47_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
48_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
49_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
50_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
51_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
52_Dropout                         -       [1, 64, 4, 16]                    -                    -
53_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
54_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
55_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
56_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
57_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
58_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
59_Dropout                         -       [1, 64, 4, 16]                    -                    -
60_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
61_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
62_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
63_Conv2d             [64, 64, 3, 3]       [1, 64, 4, 16]                36.93                 2.36
64_BatchNorm2d                  [64]       [1, 64, 4, 16]                 0.13                 0.00
65_LeakyReLU                       -       [1, 64, 4, 16]                    -                    -
66_Dropout                         -       [1, 64, 4, 16]                    -                    -
67_LSTM                            -         [1, 64, 256]               198.66                 0.20
  weight_ih_l0             [512, 64]
  weight_hh_l0            [512, 128]
  weight_ih_l0_reverse            [512, 64]
  weight_hh_l0_reverse           [512, 128]
68_Dropout                         -         [1, 64, 256]                    -                    -
69_Linear                  [256, 28]          [1, 64, 28]                 7.20                 0.01
====================================================================================================
# Params:    531.74K
# Mult-Adds: 47.52M
----------------------------------------------------------------------------------------------------